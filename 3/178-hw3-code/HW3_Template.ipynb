{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Template for HW3\n",
    "\n",
    "This notebook contains the same template code as \"logisticClassify2.py\", but reorganized to make it simpler to edit and solve in iPython.  Feel free to use this for your homework, or do it another way, as you prefer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import mltools as ml\n",
    "import sys\n",
    "sys.path.append('code')\n",
    "\n",
    "import matplotlib.pyplot as plt   # use matplotlib for plotting with inline plots\n",
    "plt.set_cmap('jet');\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore'); # for deprecated matplotlib functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = np.genfromtxt(\"data/iris.txt\",delimiter=None)\n",
    "X, Y = iris[:,0:2], iris[:,-1]   # get first two features & target\n",
    "X,Y  = ml.shuffleData(X,Y)       # reorder randomly rather than by class label\n",
    "X,_  = ml.transforms.rescale(X)  # rescale to improve numerical stability, speed convergence\n",
    "\n",
    "XA, YA = X[Y<2,:], Y[Y<2]        # Dataset A: class 0 vs class 1\n",
    "XB, YB = X[Y>0,:], Y[Y>0]        # Dataset B: class 1 vs class 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myPlotBoundary(self, X,Y):\n",
    "    \"\"\" Plot the (linear) decision boundary of the classifier, along with data \"\"\"\n",
    "    if len(self.theta) != 3: raise ValueError('Data & model must be 2D');\n",
    "    ax = X.min(0),X.max(0); ax = (ax[0][0],ax[1][0],ax[0][1],ax[1][1]);\n",
    "    ## TODO: find points on decision boundary defined by theta0 + theta1 X1 + theta2 X2 == 0\n",
    "    x1b = np.array([ax[0],ax[1]]);  # at X1 = points in x1b\n",
    "    x2b = NotImplementedError;      # TODO find x2 values as a function of x1's values\n",
    "    ## Now plot the data and the resulting boundary:\n",
    "    A = Y==self.classes[0]; # and plot it:\n",
    "    plt.plot(X[A,0],X[A,1],'b.',X[~A,0],X[~A,1],'r.',x1b,x2b,'k-'); plt.axis(ax); plt.draw();\n",
    "\n",
    "\n",
    "# Create a shell classifier\n",
    "class logisticClassify2(ml.classifier):\n",
    "    classes = []\n",
    "    theta = np.array( [-1, 0, 0] )   # initialize theta to something\n",
    "    plotBoundary = myPlotBoundary    # \n",
    "    predict = None                   # these functions will be implemented later\n",
    "    train = None\n",
    "\n",
    "learnerA = logisticClassify2()\n",
    "learnerA.classes = np.unique(YA)       # store the class values for this problem\n",
    "learnerA.theta = NotImplementedError;  # TODO: insert hard-coded values\n",
    "learnerA.plotBoundary(learnerA,XA,YA)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Should go in your logistic2 class:\n",
    "def myPredict(self,X):\n",
    "    \"\"\" Return the predictied class of each data point in X\"\"\"\n",
    "    raise NotImplementedError\n",
    "    ## TODO: compute linear response r[i] = theta0 + theta1 X[i,1] + theta2 X[i,2]  for each i\n",
    "    ## TODO: if r[i] > 0, predict class 1:  Yhat[i] = self.classes[1]\n",
    "    ##       else predict class 0:  Yhat[i] = self.classes[0]\n",
    "    return Yhat\n",
    "\n",
    "\n",
    "# Update our shell classifier definition\n",
    "class logisticClassify2(ml.classifier):\n",
    "    classes = []\n",
    "    theta = np.array( [-1, 0, 0] )   # initialize theta to something\n",
    "    plotBoundary = myPlotBoundary    # \n",
    "    predict = myPredict              \n",
    "    train = None\n",
    "\n",
    "learnerA = logisticClassify2()\n",
    "learnerA.classes = np.unique(YA)       # store the class values for this problem\n",
    "learnerA.theta = NotImplementedError;  # TODO: insert hard-coded values\n",
    "\n",
    "print \"Error: \", learnerA.err(XA,YA)\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If predict is implemented, then the inherited 2D visualization function should work; you can verify your decision boundary from P1.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml.plotClassify2D(learnerA,XA,YA)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...\n",
    "\n",
    "\n",
    "Here is an example of latex equations that may be useful for expressing the gradient:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Gradient of NLL\n",
    "\n",
    "Our negative log-likelihood loss is:\n",
    "$$J_j(\\theta) = - \\begin{cases} \\log( \\sigma(x^{(i)} \\cdot \\theta)) & \\mbox{if}\\  y^{(i)}=1 \\\\ \\log(1-\\sigma(x^{(i)} \\cdot \\theta)) & \\mbox{if}\\  y^{(i)}=0 \\end{cases}$$\n",
    "\n",
    "Thus, its gradient is:\n",
    "$$\\nabla J_j(\\theta) = (something)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6\n",
    "\n",
    "Now define the train function and complete its missing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myTrain(self, X, Y, initStep=1.0, stopTol=1e-4, stopEpochs=5000, plot=None):\n",
    "    \"\"\" Train the logistic regression using stochastic gradient descent \"\"\"\n",
    "    from IPython import display\n",
    "    M,N = X.shape;                     # initialize the model if necessary:\n",
    "    self.classes = np.unique(Y);       # Y may have two classes, any values\n",
    "    XX = np.hstack((np.ones((M,1)),X)) # XX is X, but with an extra column of ones\n",
    "    YY = ml.toIndex(Y,self.classes);   # YY is Y, but with canonical values 0 or 1\n",
    "    if len(self.theta)!=N+1: self.theta=np.random.rand(N+1);\n",
    "    # init loop variables:\n",
    "    epoch=0; done=False; Jnll=[]; J01=[];\n",
    "    while not done:\n",
    "        stepsize, epoch = initStep*2.0/(2.0+epoch), epoch+1; # update stepsize\n",
    "        # Do an SGD pass through the entire data set:\n",
    "        for i in np.random.permutation(M):\n",
    "            ri    = NotImplementedError;     # TODO: compute linear response r(x)\n",
    "            gradi = NotImplementedError;     # TODO: compute gradient of NLL loss\n",
    "            self.theta -= stepsize * gradi;  # take a gradient step\n",
    "\n",
    "        J01.append( self.err(X,Y) )  # evaluate the current error rate\n",
    "\n",
    "        ## TODO: compute surrogate loss (logistic negative log-likelihood)\n",
    "        ##  Jsur = - sum_i [ (log si) if yi==1 else (log(1-si)) ]\n",
    "        Jnll.append( NotImplementedError ) # TODO evaluate the current NLL loss\n",
    "        display.clear_output(wait=True);\n",
    "        plt.subplot(1,2,1); plt.cla(); plt.plot(Jnll,'b-',J01,'r-'); # plot losses\n",
    "        if N==2: plt.subplot(1,2,2); plt.cla(); self.plotBoundary(X,Y); # & predictor if 2D\n",
    "        plt.pause(.01);                    # let OS draw the plot        \n",
    "\n",
    "        ## For debugging: you may want to print current parameters & losses\n",
    "        # print self.theta, ' => ', Jnll[-1], ' / ', J01[-1]\n",
    "        # raw_input()   # pause for keystroke\n",
    "\n",
    "        # TODO check stopping criteria: exit if exceeded # of epochs ( > stopEpochs)\n",
    "        done = NotImplementedError;   # or if Jnll not changing between epochs ( < stopTol )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update our shell classifier definition\n",
    "class logisticClassify2(ml.classifier):\n",
    "    classes = []\n",
    "    theta = np.array( [-1, 0, 0] )   # initialize theta to something\n",
    "    plotBoundary = myPlotBoundary    # \n",
    "    predict = myPredict              # Now all parts are implemented\n",
    "    train = myTrain\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,5)    # make a wide figure, for two subplots\n",
    "    \n",
    "learnerA = logisticClassify2()\n",
    "learnerA.theta = np.array([0.,0.,0.]);\n",
    "learnerA.train(XA,YA,initStep=1e-1,stopEpochs=1000,stopTol=1e-5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml.plotClassify2D(learnerA,XA,YA)\n",
    "print(\"Training error rate: \",learnerA.err(XA,YA))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
